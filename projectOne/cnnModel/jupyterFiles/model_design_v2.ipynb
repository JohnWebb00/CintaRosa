{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8cb0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Authors:\n",
    "- bardiaf - ??\n",
    "- ...\n",
    "\n",
    "Usage: None\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import imghdr\n",
    "import pathlib\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d409e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = 'C:/users/georg/Downloads/data/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3805179",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exist = ['jpeg', 'jpg', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3787417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 588 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('C:/users/georg/Downloads/data/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f8fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024e5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e40e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x / 255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0745ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .7)\n",
    "validation_size = int(len(data) * .2) + 1\n",
    "test_size = int(len(data) * .1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16acf31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(train_size)\n",
    "validation_data = data.skip(train_size).take(validation_size)\n",
    "test_data = data.skip(train_size + validation_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e933aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout layer\n",
    "model.add(Dense(3, activation='softmax'))  # Output layer with 3 neurons (0, 1, 2)\n",
    "\n",
    "    \n",
    "model.compile(optimizer=keras.optimizers.Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf99e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory = 'C:/users/georg/Downloads/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa730ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc60488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 256, 256, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 256, 256, 3)\n    \n    Call arguments received by layer \"sequential\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file27iz8ie9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 256, 256, 3)\n    \n    Call arguments received by layer \"sequential\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=50, batch_size=100, validation_data=validation_data, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16865e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize / 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad461285",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(yhat)\n",
    "\n",
    "if predicted_class == 0:\n",
    "    print('benign')\n",
    "elif predicted_class == 1:\n",
    "    print('malignant')\n",
    "else:\n",
    "    print('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8eab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(image_path):\n",
    "    \n",
    "    scale_factor = 1 / 255.0\n",
    "    \n",
    "    # It ensures image_path is a string\n",
    "    if not isinstance(image_path, str):\n",
    "        raise ValueError(\"Image path should be a string.\")\n",
    "\n",
    "    # It reads the image and converts it to grayscale\n",
    "    img = Image.open(image_path).convert('L')\n",
    "            \n",
    "    # It checks if the image is successfully read\n",
    "    if img is None:\n",
    "         raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
    "\n",
    "    # It resizes the image using to (256, 256)\n",
    "    resized_img = img.resize((256, 256))\n",
    "    \n",
    "    # It converts the resized image to NumPy array\n",
    "    img_array = np.array(resized_img, dtype = 'float32') * scale_factor\n",
    "\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_csv(input_directory, output_csv_path):\n",
    "    \n",
    "    write_header = not os.path.exists(output_csv_path)\n",
    "    # Open the CSV file in append mode\n",
    "    with open(output_csv_path, 'a', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        if write_header:\n",
    "            header_row = [f'P-{i}' for i in range(256 * 256)]\n",
    "            csv_writer.writerow(header_row)\n",
    "\n",
    "        # Process each image in the input directory\n",
    "        for filename in os.listdir(input_directory):\n",
    "            if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "                image_path = join(input_directory, filename)\n",
    "\n",
    "                img_array = to_numpy(image_path)\n",
    "\n",
    "                # Reshape the 2D array into a 1D array\n",
    "                flattened_array = img_array.flatten()\n",
    "                \n",
    "                if \"malignant\" in filename:\n",
    "                    label = 1\n",
    "                elif \"benign\" in filename:\n",
    "                    label = 0\n",
    "                elif \"normal\" in filename:\n",
    "                    label = 2\n",
    "                else:\n",
    "                    label = -1  # Placeholder for other labels\n",
    "\n",
    "                 # Write it to the CSV file\n",
    "                #csv_writer.writerow(flattened_array)\n",
    "                csv_writer.writerow([label] + list(flattened_array))\n",
    "\n",
    "    print(f\"Images in '{input_directory}' have been converted and appended to the CSV file '{output_csv_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#malignant_directory = \"/Users/bardiaforooraghi/Downloads/data/normal/\"\n",
    "csv_file_path = 'C:/users/georg/Downloads/benign.csv'\n",
    "\n",
    "images_to_csv(malignant_directory, csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1da260",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_test_df = pd.read_csv('C:/users/georg/Downloads/benign.csv', sep = ',')\n",
    "\n",
    "formatted_df = fashion_test_df.head().to_string(index=True, header=True)\n",
    "\n",
    "print(formatted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52076e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/users/georg/Downloads/breastCancerModel_v1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
